
#sudo /etc/init.d/nginx start
#sudo cp -f /mnt/c/BMSTU_7sem_web/nginx/conf/nginx_for_ubuntu.conf /etc/nginx/nginx.conf
# sudo rm -rf /home/alena/cache/nginx/*
# cat /var/log/nginx/error.log
# cat /var/log/nginx/access.log
# ipconfig
# ip a

# docker-compose -f /mnt/c/BMSTU_7sem_web/src/tarantool/docker-compose.yml up -d
# docker-compose -f /mnt/c/BMSTU_7sem_web/src/tarantool/docker-compose.yml down
# ps -ax | grep nginx

# netstat -an | grep 5000
#netstat -an | findstr 5000
# wget http://127.0.0.1:5000
# ping "$(hostname).local"
#cat /etc/resolv.conf

worker_processes  auto;
events {
    worker_connections  1024;
}


http {

	# 8. кеширование “/home/alena/cache/nginx” указывает путь хранения кэша на сервере. Именно в эту директорию (надо создать самому) nginx будет сохранять те самые файлы с ответом от бэкенда. 
	#“levels=1:2” — задает уровень вложенности директорий с кэшем. 
	# Уровни вложенности указываются через “:”, в данном случае будет созданы 2 директории,
	# всего допустимо 3 уровня вложенности. Для каждого уровня вложенности доступны значения от 1 до 2, 
	# указывающие, как формировать имя директории.
	# “keys_zone=proxy_cache:15m” параметр задает имя зоны в разделяемой памяти, где хранятся все активные ключи и информация по ним. 
	# Через “:” указывается размер выделяемой памяти в Мб.
	# “max_size=1G” определяет максимальный размер кэша для всех страниц, при превышении которого nginx сам позаботится об удалении менее востребованных данных.
	proxy_cache_path /home/alena/cache/nginx levels=1:2 keys_zone=all:32m max_size=1g;
	
	# 6. Настроить Nginx в части балансировки: запустить еще 2 инстанса бэкенда на других портах с правами доступа в базу данных только на чтение и настроить
	# балансировку GET запросов к /api/v1 (/api/v2) в NGINX на 3 бэкенда в соотношении 2:1:1, где первый - основной бэкенд-сервер.
	upstream backend {
		#server 172.26.16.1:5000 weight=2;
		#server 172.26.16.1:5004;
		#server 172.26.16.1:5006;
		
		server 172.17.0.1:5000 weight=2;
		server 172.17.0.1:5004;
		server 172.17.0.1:5006;
	}
	
	upstream main_backend {
		#server 172.26.16.1:5000;
		server 172.17.0.1:5000;
	}
	
	# переменная содержит бекенд, на который надо пойти (upstream_location)
	# Это директива, которая устанавливает значение одной переменной (правой), в зависимости от другой (левой). если то если то
	map $request_method $upstream_location { 
        GET     backend;  # у остальных двух есть право только на чтение
        default main_backend;
    }
    
	# если пишут  /api/v1/{smth} -> /smth
	# /api/v1/statistics -> /statistics
	map $request_uri $api_uri { 
        ~^/api/v1(.*)$ $1;
    }





    server {
listen localhost;
	# удоли listen 172.21.48.1:5000;
		# 8. сжатие	
		gzip on; # включаем сжатие
		gzip_disable "msie6"; # отключаем сжатие для старья (исключаем IE6 из браузеров, которые будут получать сжатые файлы. (не поддерживает GZIP ))
		# определяет MIME типы, для которых будет работать сжатие
		gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript image/jpeg;
		
		
		
		
		
		# proxy_pass_header поле; Разрешает передавать от проксируемого сервера клиенту запрещённые для передачи поля заголовка.
        #По умолчанию nginx не передаёт клиенту поля заголовка “Date”, “Server”, “X-Pad” и “X-Accel-...” из ответа проксированного сервера.
		# https://serverfault.com/questions/499343/why-proxy-pass-header-server
		#This is required for compliance with HTTP/1.1 which states that Server is an origin header:
		proxy_pass_header Server;



		# 8. кеширование
		proxy_cache_methods GET;
		# Задаёт число запросов, после которого ответ будет закэширован.
        proxy_cache_min_uses 1; 
		# Задаёт время кэширования для разных кодов ответа. 
		proxy_cache_valid 200 302 10m;
		proxy_cache_valid 404 1m;
		
		
		# server_name se.com; вроде не надо
        # server_name localhost; было
		# server_name se.com;
		server_name se.com;
		
		
		# Задание 5. a 
		# Настроить маршрутизацию /api/v1 (/api/v2) на подготовленное REST API
		#http://127.0.0.1/api/v1/lifts/A0
		location /api/v1/ {
            proxy_pass http://$upstream_location$api_uri;
			proxy_no_cache 1;
		}
		
		# Задание 5.b
		# По пути /api/v1 (/api/v2) отдавать swagger
		#http://127.0.0.1/api/v1/
		location = /api/v1/ {
			proxy_pass http://backend/swagger; # именно без /
			#proxy_pass http://backend/swagger/index.html;
			proxy_no_cache 1;
		}
		
		
		# Задание 5.d
        # http://localhost/ и http://localhost http://127.0.0.1/
        # Настроить / на отдачу статики (в будущем - SPA-приложения). 
        # Пока положить приветственный HTML (/static/index.html) с картинкой (static/img/image.jpg).
		location / {
			root /mnt/c/BMSTU_7sem_web/static;
		}
		
		# Задание 5.c (работает благодаря d)
		# на /legacy сделать страничку с ссылкой на загрузку десктопной/консольной версии.
		# http://127.0.0.1/legacy
		#location /legacy/ {
		#	root /mnt/c/BMSTU_7sem_web/static;
		#}
		
		# Задание 5.e
        # http://localhost/test/ и http://localhost/test http://127.0.0.1/test
        # Настроить /test на отдачу той же страницы, что и /
        location /test {
            #rewrite ^/test/(.*)$ /$1 last;
            return 301 $scheme://$http_host/;
        }
		

		# Задание 5.f
		# Настроить /admin на проксирование в админку базы данных (любую стандартную).
		# http://127.0.0.1/admin
		location /admin {
			return 301 http://localhost:8000/;
		}
		
		
		
		# Задание 5.g
        # http://localhost/status (без /) http://127.0.0.1/status
        location = /status {
            stub_status;
        }
		
		
		
		# http://localhost/api/v1/
		
		# http://172.26.16.1/api/v1
		# Техническая информация: ошибка connectionfailure
		
		
		#http://localhost/api/v1/
		# *13 connect() failed (111: Connection refused) while connecting to upstream, client: 127.0.0.1, server: 127.0.0.1, request: "GET /api/v1/ HTTP/1.1", upstream: "http://127.0.0.1:5000/swagger", host: "localhost"
		
		
# http://localhost:5004/swagger/ -> http://localhost:5004/swagger/index.html
        
    }


}


# sudo docker container inspect tarantool_ski_resort
# "ski_admin:Tty454r293300@localhost:3301"
